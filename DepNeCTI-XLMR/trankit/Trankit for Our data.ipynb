{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NwtnrdQMd1Zg","executionInfo":{"status":"ok","timestamp":1689363288231,"user_tz":-330,"elapsed":19575,"user":{"displayName":"Anonymous Panda","userId":"05991190291010998383"}},"outputId":"0cca9800-53e1-408e-b1e5-a1c08929da84"},"id":"NwtnrdQMd1Zg","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install tokenizers\n","!pip install sentencepiece\n","!pip install sacremoses\n","!pip install transformers\n","!pip install langid"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pqxG0fVepov","executionInfo":{"status":"ok","timestamp":1689363328827,"user_tz":-330,"elapsed":32826,"user":{"displayName":"Anonymous Panda","userId":"05991190291010998383"}},"outputId":"02facf66-37ae-4b0f-81a7-11b1bc5c0cf8"},"id":"4pqxG0fVepov","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tokenizers\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.13.3\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2022.10.31)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.65.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=fc447187e520642b3cf026efacde8d5b83b94a525c3bc518929954c92f60e289\n","  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n","Successfully built sacremoses\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.0.53\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Collecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 transformers-4.30.2\n","Collecting langid\n","  Downloading langid-1.1.6.tar.gz (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from langid) (1.22.4)\n","Building wheels for collected packages: langid\n","  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=f0a1693761784a95c41e61b6997f1b4147adf6c79262ccd74f4ee971456a2f86\n","  Stored in directory: /root/.cache/pip/wheels/23/c8/c6/eed80894918490a175677414d40bd7c851413bbe03d4856c3c\n","Successfully built langid\n","Installing collected packages: langid\n","Successfully installed langid-1.1.6\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/trankit-master'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UEBCO3ROtVsO","executionInfo":{"status":"ok","timestamp":1689363368406,"user_tz":-330,"elapsed":422,"user":{"displayName":"Anonymous Panda","userId":"05991190291010998383"}},"outputId":"e3fecd5c-696f-4175-ed14-01ec6c7c3757"},"id":"UEBCO3ROtVsO","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/trankit-master\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0OpqR97mU4r","executionInfo":{"status":"ok","timestamp":1689363370873,"user_tz":-330,"elapsed":427,"user":{"displayName":"Anonymous Panda","userId":"05991190291010998383"}},"outputId":"721c2ef5-329a-46f4-c517-d714a1364b4e"},"id":"G0OpqR97mU4r","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdocs\u001b[0m/      LICENSE      README.md      setup.py  \u001b[01;34mTrankit_Data\u001b[0m/\n","\u001b[01;34mexamples\u001b[0m/  MANIFEST.in  \u001b[01;34mSaved_Models\u001b[0m/  \u001b[01;34mtrankit\u001b[0m/\n"]}]},{"cell_type":"code","source":["import sys\n","# sys.path.append('/content/drive/MyDrive/trankit-master')\n","\n","from trankit import tpipeline\n","from trankit.tpipeline import TPipeline as tpip\n","from trankit.iterators.tagger_iterators import TaggerDataset\n","import os\n","import re\n","\n","def lines_to_relations(true_lines):\n","\n","    relations_list = []\n","    relations_oneline = []\n","    for line in true_lines:\n","        if line == '\\n':\n","            relations_oneline = [relation for relation in relations_oneline if (relation[2]!= 'No_rel' and relation[2]!= 'root')]\n","            relations_list.append(relations_oneline)\n","            relations_oneline = []\n","        else:\n","            lst = line.strip().split('\\t')\n","            relation = [lst[0],lst[6],lst[7]]\n","            relations_oneline.append(relation)\n","\n","    return relations_list\n","\n","def comps_from_relations(relations):\n","    lst = []\n","    nested_comp = []\n","    for rel in relations:\n","        if 'Comp_root' in rel:\n","            lst.append(rel)\n","            nested_comp.append(lst)\n","            lst = []\n","        else:\n","            lst.append(rel)\n","    return nested_comp\n","\n","def spans_from_comps(comps_list):\n","    comps_list_new = []\n","    for comps in comps_list:\n","        comps_new = []\n","        for comp in comps:\n","            comp = re.sub(',\\w+$','',comp)\n","            comp_ = re.findall('\\d+',comp)\n","            comps_new.append(comp_)\n","        comps_list_new.append(comps_new)\n","\n","    return comps_list_new\n","\n","def metric(true_lines, pred_lines,setting_name):\n","    true_relations = lines_to_relations(true_lines)\n","    pred_relations = lines_to_relations(pred_lines)\n","    correct = 0\n","    predict_count = 0\n","    true_count = 0\n","    match = []\n","    true_labels = []\n","    em = 0\n","    tot_comps = 0\n","    for i in range(len(pred_relations)):\n","\n","        true_relation_oneline = true_relations[i]\n","        pred_relation_oneline = pred_relations[i]\n","#         print(true_relation_oneline)\n","        tr_copy = [','.join(lst) for lst in true_relation_oneline]\n","        pr_copy = [','.join(lst) for lst in pred_relation_oneline]\n","\n","        tr_comps = comps_from_relations(tr_copy)\n","        pr_comps = comps_from_relations(pr_copy)\n","#         print(tr_comps)\n","        for comp in pr_comps:\n","            if comp in tr_comps:\n","                em += 1\n","        tot_comps += len(tr_comps)\n","#         if set(tr_copy) == set(pr_copy):\n","#             em += 1\n","        for rel in pred_relation_oneline:\n","            if rel in true_relation_oneline:\n","                correct += 1\n","        predict_count += len(pred_relation_oneline)\n","        true_count += len(true_relation_oneline)\n","\n","    if correct == 0:\n","        p = 0\n","        r = 0\n","    else:\n","        p = correct / predict_count\n","        r = correct / true_count\n","    if p == 0 or r == 0:\n","        f1 = 0\n","    else:\n","        f1 = 2 * p * r / (p + r)\n","    a = 1.0*correct/(predict_count+true_count-correct)\n","#     em_per = em/len(pred_relations)\n","    em_per = em/tot_comps\n","    metrics_list = [100*p, 100*r, 100*f1, 100*a, 100*em_per]\n","#     metrics_list = [100*p, 100*r, 100*f1]\n","    metrics = [round(i,2) for i in metrics_list]\n","    print(f'Results for {setting_name} are:\\n')\n","    print(f'Precision: {metrics[0]}\\nRecall: {metrics[1]}\\nF1: {metrics[2]}\\nExact match: {metrics[4]}\\n')\n","    return metrics\n","\n","def train_and_test(setting_name):\n","\n","  save_dir = './Saved_Models/'+setting_name\n","  train_file = './Trankit_Data/'+setting_name+'/train.conllu'\n","  dev_file = './Trankit_Data/'+setting_name+'/dev.conllu'\n","  test1 = './Trankit_Data/'+setting_name+'/test.conllu'\n","  test2 = './Trankit_Data/'+setting_name+'/outofDomain.conllu'\n","  test_files = [test1,test2]\n","  trainer = tpip(\n","      training_config={\n","      'category': 'customized-mwt-ner', # pipeline category\n","      'task': 'posdep', # task name\n","      'save_dir': save_dir, # directory for saving trained model\n","      'train_conllu_fpath': train_file, # annotations file in CONLLU format  for training\n","      'dev_conllu_fpath': dev_file # annotations file in CONLLU format for development\n","      # 'max_epoch': 1\n","      }\n","  )\n","\n","  # start training\n","  trainer.train()\n","  for x in range(2):\n","    test_set = TaggerDataset(\n","        config=trainer._config,\n","        gold_conllu=test_files[x],\n","        input_conllu = test_files[x],\n","        evaluate=False\n","    )\n","    test_set.numberize()\n","    test_batch_num = len(test_set) // trainer._config.batch_size + (len(test_set) % trainer._config.batch_size != 0)\n","    result = trainer._eval_posdep(data_set=test_set, batch_num=test_batch_num,\n","                              name='test', epoch=-1)\n","    os.rename(os.path.join(save_dir,'xlm-roberta-base/customized-mwt-ner/preds/tagger.test.conllu.epoch--1'), os.path.join(save_dir,'xlm-roberta-base/customized-mwt-ner/preds/tagger.test'+str(x)+' '+setting_name+'.conllu.epoch--1'))\n","    pred_conllu = os.path.join(save_dir,'xlm-roberta-base/customized-mwt-ner/preds/tagger.test'+str(x)+' '+setting_name+'.conllu.epoch--1')\n","    gold_conllu = test_files[x]\n","    with open(gold_conllu) as t:\n","      with open(pred_conllu) as p:\n","          true_lines = t.readlines()\n","          pred_lines = p.readlines()\n","    metrics = metric(true_lines,pred_lines,setting_name+str(x))\n","\n","Data_folder = './Trankit_Data'\n","lst = []\n","for path,subdirs,files in os.walk(Data_folder):\n","  if 'Trankit' not in os.path.basename(path):\n","    setting_name = os.path.basename(path)\n","    print(setting_name)\n","    train_and_test(setting_name)"],"metadata":{"id":"f3Kz_dLfeZ6Z","executionInfo":{"status":"error","timestamp":1689365942039,"user_tz":-330,"elapsed":197859,"user":{"displayName":"Anonymous Panda","userId":"05991190291010998383"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1f193fdc-28a8-4ac1-e568-035bfa061532"},"id":"f3Kz_dLfeZ6Z","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["With Context Coarse\n","Setting up training config...\n","Loaded 11000 entries from ./Trankit_Data/With Context Coarse/train.conllu\n","Loaded 2000 entries from ./Trankit_Data/With Context Coarse/dev.conllu\n","******************************\n","Posdep tagger: Epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["Train 0: 688it [01:12,  9.53it/s]\n","dev 0: 100%|█████████████████████████████| 125/125 [00:07<00:00, 17.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving adapter weights to ... ./Saved_Models/With Context Coarse/xlm-roberta-base/customized-mwt-ner/customized-mwt-ner.tagger.mdl (11.48 MB)\n","------------------------------ Best dev CoNLLu score: epoch 0------------------------------\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |    100.00 |    100.00 |    100.00 |\n","Sentences  |    100.00 |    100.00 |    100.00 |\n","Words      |    100.00 |    100.00 |    100.00 |\n","UPOS       |    100.00 |    100.00 |    100.00 |    100.00\n","XPOS       |    100.00 |    100.00 |    100.00 |    100.00\n","UFeats     |    100.00 |    100.00 |    100.00 |    100.00\n","AllTags    |    100.00 |    100.00 |    100.00 |    100.00\n","Lemmas     |      0.00 |      0.00 |      0.00 |      0.00\n","UAS        |    100.00 |    100.00 |    100.00 |    100.00\n","LAS        |     82.71 |     82.71 |     82.71 |     82.71\n","CLAS       |    100.00 |    100.00 |    100.00 |    100.00\n","MLAS       |    100.00 |    100.00 |    100.00 |    100.00\n","BLEX       |      0.00 |      0.00 |      0.00 |      0.00\n","\n","Loaded 2940 entries from ./Trankit_Data/With Context Coarse/test.conllu\n"]},{"output_type":"stream","name":"stderr","text":["test -1: 100%|███████████████████████████| 184/184 [00:10<00:00, 17.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Results for With Context Coarse0 are:\n","\n","Precision: 56.7\n","Recall: 51.86\n","F1: 54.17\n","Exact match: 16.18\n","\n","Loaded 1139 entries from ./Trankit_Data/With Context Coarse/outofDomain.conllu\n"]},{"output_type":"stream","name":"stderr","text":["test -1: 100%|█████████████████████████████| 72/72 [00:02<00:00, 31.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Results for With Context Coarse1 are:\n","\n","Precision: 57.4\n","Recall: 52.65\n","F1: 54.92\n","Exact match: 17.03\n","\n","With Context Finegrain\n","Setting up training config...\n","Loaded 11000 entries from ./Trankit_Data/With Context Finegrain/train.conllu\n","Loaded 2000 entries from ./Trankit_Data/With Context Finegrain/dev.conllu\n","******************************\n","Posdep tagger: Epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["Train 0:  56%|███████████████            | 382/687 [00:41<00:34,  8.72it/s]"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-fcd23e5af0a5>\u001b[0m in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0msetting_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-fcd23e5af0a5>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(setting_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     test_set = TaggerDataset(\n","\u001b[0;32m/content/drive/MyDrive/trankit-master/trankit/tpipeline.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_mwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'posdep'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_posdep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lemmatize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_lemma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/trankit-master/trankit/tpipeline.py\u001b[0m in \u001b[0;36m_train_posdep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_parameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clipping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"gdPJSW7g7lmi"},"id":"gdPJSW7g7lmi","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}