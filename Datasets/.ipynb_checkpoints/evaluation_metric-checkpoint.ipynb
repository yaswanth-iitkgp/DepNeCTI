{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d098d7",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "This is the evaluation script for the data of NeCTIS model and it's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77327b",
   "metadata": {},
   "source": [
    "## Evaluation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_to_relations(true_lines):\n",
    "    \n",
    "    relations_list = []\n",
    "    relations_oneline = []\n",
    "    for line in true_lines:\n",
    "#         print(line)\n",
    "        if line == '\\n':\n",
    "            relations_oneline = [relation for relation in relations_oneline if (relation[2]!= 'No_rel' and relation[2]!= 'root')]\n",
    "#             print(relations_oneline,'\\n')\n",
    "            relations_list.append(relations_oneline)\n",
    "            relations_oneline = []\n",
    "        else:\n",
    "            lst = line.strip().split('\\t')\n",
    "            relation = [lst[0],lst[4],lst[5]]\n",
    "            relations_oneline.append(relation)\n",
    "    \n",
    "    return relations_list\n",
    "\n",
    "# lines_to_relations(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comps_from_relations(relations):\n",
    "    lst = []\n",
    "    nested_comp = []\n",
    "    for rel in relations:\n",
    "        if 'Comp_root' in rel:\n",
    "            lst.append(rel)\n",
    "            nested_comp.append(lst)\n",
    "            lst = []\n",
    "        else:\n",
    "            lst.append(rel)\n",
    "    return nested_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(true_lines, pred_lines):\n",
    "    true_relations = lines_to_relations(true_lines)\n",
    "    pred_relations = lines_to_relations(pred_lines)\n",
    "    correct = 0\n",
    "    predict_count = 0\n",
    "    true_count = 0\n",
    "    match = []\n",
    "    true_labels = []\n",
    "    em = 0\n",
    "    tot_comps = 0\n",
    "    for i in range(len(pred_relations)):\n",
    "        \n",
    "        true_relation_oneline = true_relations[i]\n",
    "        pred_relation_oneline = pred_relations[i]\n",
    "#         print(true_relation_oneline)\n",
    "        tr_copy = [','.join(lst) for lst in true_relation_oneline]\n",
    "        pr_copy = [','.join(lst) for lst in pred_relation_oneline]\n",
    "        \n",
    "        tr_comps = comps_from_relations(tr_copy)\n",
    "        pr_comps = comps_from_relations(pr_copy)\n",
    "#         print(tr_comps)\n",
    "        for comp in pr_comps:\n",
    "            if comp in tr_comps:\n",
    "                em += 1\n",
    "        tot_comps += len(tr_comps)\n",
    "#         if set(tr_copy) == set(pr_copy):\n",
    "#             em += 1\n",
    "        for rel in pred_relation_oneline:\n",
    "            if rel in true_relation_oneline:\n",
    "                correct += 1\n",
    "        predict_count += len(pred_relation_oneline)\n",
    "        true_count += len(true_relation_oneline)\n",
    "\n",
    "    if correct == 0:\n",
    "        p = 0\n",
    "        r = 0\n",
    "    else:\n",
    "        p = correct / predict_count\n",
    "        r = correct / true_count\n",
    "    if p == 0 or r == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * p * r / (p + r)\n",
    "    a = 1.0*correct/(predict_count+true_count-correct)\n",
    "#     em_per = em/len(pred_relations)\n",
    "    em_per = em/tot_comps\n",
    "    metrics_list = [100*p, 100*r, 100*f1, 100*a, 100*em_per]\n",
    "#     metrics_list = [100*p, 100*r, 100*f1]\n",
    "    metrics_list = [round(i,2) for i in metrics_list]\n",
    "\n",
    "    return metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '' #Put the path of the folder you have the predictions of, to get the evaluation metrics.\n",
    "lst = []\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        lst.append(os.path.join(path, name))\n",
    "true_files = [x for x in lst if 'gold' in x]\n",
    "pred_files = [x for x in lst if 'pred' in x]\n",
    "for i in range(len(true_files)):\n",
    "    true_file = true_files[i] #ground truth file path\n",
    "    pred_file = pred_files[i] #predictions file path\n",
    "    with open(true_file) as t:\n",
    "        with open(pred_file) as p:\n",
    "            true_lines = t.readlines()\n",
    "            pred_lines = p.readlines()\n",
    "\n",
    "    metrics = metric(true_lines,pred_lines)\n",
    "    print(f'Results for {true_file} are:\\n')\n",
    "    print(f'Precision: {metrics[0]}\\nRecall: {metrics[1]}\\nF1: {metrics[2]}\\nExact match: {metrics[4]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
